{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d3043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved to everli_store_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import socket\n",
    "import uuid\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import tempfile\n",
    "import logging\n",
    "import glob\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Tuple, Optional, Dict, Any\n",
    "from DrissionPage import ChromiumPage, ChromiumOptions\n",
    "import pandas as pd\n",
    "import random \n",
    "import secrets\n",
    "from pytz import timezone\n",
    "\n",
    "# Add timezone for Dubai if needed\n",
    "zone_dubai = timezone('Asia/Dubai')\n",
    "source_file_ID = 267162\n",
    "stores=pd.read_csv(\"stores.csv\")\n",
    "class SimplifiedTokenExtractor:    \n",
    "    def __init__(self, page, logger):\n",
    "        self.page = page\n",
    "        self.logger = logger\n",
    "        self.captured_token = None    \n",
    "    def extract_vauth_token_from_cookies(self) -> Optional[str]:\n",
    "        try:\n",
    "            self.logger.log_info(\"Attempting to extract vAuthToken from cookies\")\n",
    "            time.sleep(3)\n",
    "            cookies = self.page.cookies()\n",
    "            for cookie in cookies:\n",
    "                cookie_name = cookie.get('name', '')\n",
    "                cookie_value = cookie.get('value', '')\n",
    "                if cookie_name == 'vAuthToken' and cookie_value:\n",
    "                    if len(cookie_value) > 10 and cookie_value != 'null':\n",
    "                        self.logger.log_success(f\"vAuthToken found in cookies: {cookie_value}\")\n",
    "                        self.captured_token = cookie_value\n",
    "                        return cookie_value   \n",
    "            self.logger.log_warning(\"vAuthToken cookie not found\")\n",
    "            return None                \n",
    "        except Exception as e:\n",
    "            self.logger.log_error(f\"Error extracting vAuthToken from cookies: {e}\")\n",
    "            return None\n",
    "class HeaderManager:    \n",
    "    def __init__(self, logger):\n",
    "        self.logger = logger\n",
    "        self.session_id = None\n",
    "        self.device_fingerprint = None\n",
    "    def get_headers_for_api_call(self, \n",
    "                                authentication_token: str,\n",
    "                                request_type: str = 'GET',\n",
    "                                endpoint_url: str = '',\n",
    "                                referer: Optional[str] = None) -> Dict[str, str]:\n",
    "        base_headers = self.generate_base_headers(authentication_token)\n",
    "        \n",
    "        if referer:\n",
    "            base_headers['referer'] = referer\n",
    "        self.logger.log_debug(f\"Generated headers for {request_type} {endpoint_url}\")\n",
    "        self.logger.log_debug(f\"Auth header present: {'authorization' in base_headers}\")\n",
    "\n",
    "        return base_headers\n",
    "    def generate_device_fingerprint(self) -> str:\n",
    "        \"\"\"Generate a consistent device fingerprint for the session\"\"\"\n",
    "        if not self.device_fingerprint:\n",
    "            self.device_fingerprint = str(uuid.uuid4())\n",
    "        return self.device_fingerprint\n",
    "    def generate_session_id(self) -> str:\n",
    "        \"\"\"Generate a session ID that persists across requests\"\"\"\n",
    "        if not self.session_id:\n",
    "            self.session_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, secrets.token_hex(8)))\n",
    "        return self.session_id\n",
    "    def get_random_user_agent(self) -> str:\n",
    "        user_agents = [\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36',\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36'\n",
    "        ]\n",
    "        return random.choice(user_agents)\n",
    "    def get_random_screen_resolution(self) -> str:\n",
    "        \"\"\"Get a random but common screen resolution\"\"\"\n",
    "        resolutions = [\n",
    "            \"1920x1080\", \"1366x768\", \"1536x864\", \"1440x900\",\n",
    "            \"1280x720\", \"1600x900\", \"1024x768\", \"1680x1050\"\n",
    "        ]\n",
    "        return random.choice(resolutions)\n",
    "    def generate_base_headers(self, authentication_token: Optional[str] = None) -> Dict[str, str]:\n",
    "        \"\"\"Generate base headers that should be consistent across requests\"\"\"\n",
    "        headers = {\n",
    "            'accept': 'application/json, text/plain, */*',\n",
    "            'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8',\n",
    "            'if-none-match': 'W/\"50d7e1bef6bfcedccfeec1e1b5e1fb9b\"',\n",
    "            'origin': 'https://it.everli.com',\n",
    "            'priority': 'u=1, i',\n",
    "            'referer': 'https://it.everli.com/',\n",
    "            'sec-ch-ua': '\"Chromium\";v=\"136\", \"Google Chrome\";v=\"136\", \"Not.A/Brand\";v=\"99\"',\n",
    "            'sec-ch-ua-mobile': '?0',\n",
    "            'sec-ch-ua-platform': '\"Windows\"',\n",
    "            'sec-fetch-dest': 'empty',\n",
    "            'sec-fetch-mode': 'cors',\n",
    "            'sec-fetch-site': 'same-site',\n",
    "            'user-agent': self.get_random_user_agent(),\n",
    "            'x-s24-client': 'website/8.4.1',\n",
    "            'x-s24-country': 'ITA',\n",
    "            'x-s24-device-resolution': self.get_random_screen_resolution(),\n",
    "            'x-s24-tracking': 'false',\n",
    "            'x-s24-whitelabel': 'it.everli.com',\n",
    "            'user-session': self.generate_session_id(),\n",
    "            'x-device-id': self.generate_device_fingerprint(),\n",
    "        }  \n",
    "        if authentication_token:\n",
    "            token = str(authentication_token).strip().strip('\"\\'')\n",
    "            if token and token != 'null':\n",
    "                if not token.startswith('Bearer '):\n",
    "                    token = f'Bearer {token}'\n",
    "                headers['authorization'] = token\n",
    "        return headers\n",
    "class StructuredLogger:\n",
    "    \"\"\"CSV-only structured logger for scraper operations\"\"\"\n",
    "    \n",
    "    def __init__(self, log_dir: str, scraper_name: str, source: str, schedule: str, machine_id: str, job_id: int = 1):\n",
    "        self.log_dir = log_dir\n",
    "        self.scraper_name = scraper_name\n",
    "        self.source = source\n",
    "        self.schedule = schedule\n",
    "        self.machine_id = machine_id\n",
    "        self.job_id = job_id\n",
    "        self.start_time = time.time()\n",
    "        self.last_step_time = self.start_time\n",
    "        self.machine_ip = self._get_machine_ip()  \n",
    "        \n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        \n",
    "        self.csv_log_path = os.path.join(log_dir, f'Everli_scraper_logs_{datetime.now().strftime(\"%Y-%m-%d\")}.csv')\n",
    "        self._setup_csv_logger()\n",
    "        \n",
    "        self.current_category = \"\"\n",
    "        self.current_subcategory = \"\"\n",
    "        self.current_product_url = \"\"\n",
    "        self.current_status = \"in_progress\"\n",
    "    \n",
    "    def _get_machine_ip(self) -> str:\n",
    "        \"\"\"Get the machine's IP address\"\"\"\n",
    "        try:\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n",
    "                s.connect((\"8.8.8.8\", 80))\n",
    "                local_ip = s.getsockname()[0]\n",
    "                return local_ip\n",
    "        except Exception:\n",
    "            try:\n",
    "                hostname = socket.gethostname()\n",
    "                local_ip = socket.gethostbyname(hostname)\n",
    "                return local_ip\n",
    "            except Exception:\n",
    "                return \" \"\n",
    "    \n",
    "    def _setup_csv_logger(self):\n",
    "        \"\"\"Setup CSV logging with headers\"\"\"\n",
    "        self.csv_fieldnames = [\n",
    "            'asctime', 'levelname', 'filename', 'funcName', 'lineno',\n",
    "            'scraper_name', 'source', 'schedule', 'machine_id', 'job_id',\n",
    "            'category', 'subcategory', 'product_url', 'step_duration',\n",
    "            'total_duration_from_start', 'status', 'error_message', \n",
    "            'data_size', 'inconsistent_data_count', 'machine_autofetch', 'message'\n",
    "        ]\n",
    "        \n",
    "        if not os.path.exists(self.csv_log_path):\n",
    "            with open(self.csv_log_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=self.csv_fieldnames)\n",
    "                writer.writeheader()\n",
    "    \n",
    "    def _get_caller_info(self):\n",
    "        \"\"\"Get information about the calling function\"\"\"\n",
    "        import inspect\n",
    "        frame = inspect.currentframe()\n",
    "        try:\n",
    "            caller_frame = frame.f_back.f_back.f_back\n",
    "            if caller_frame:\n",
    "                return {\n",
    "                    'filename': os.path.basename(caller_frame.f_code.co_filename),\n",
    "                    'funcName': caller_frame.f_code.co_name,\n",
    "                    'lineno': caller_frame.f_lineno\n",
    "                }\n",
    "        finally:\n",
    "            del frame\n",
    "        return {'filename': 'unknown', 'funcName': 'unknown', 'lineno': 0}\n",
    "    \n",
    "    def _format_total_duration(self, total_seconds: float) -> str:\n",
    "        \"\"\"Format total duration in xxH:xxMIN:xxSECONDS format\"\"\"\n",
    "        hours = int(total_seconds // 3600)\n",
    "        minutes = int((total_seconds % 3600) // 60)\n",
    "        seconds = int(total_seconds % 60)\n",
    "        return f\"{hours:02d}H:{minutes:02d}MIN:{seconds:02d}SECONDS\"\n",
    "    \n",
    "    def _extract_error_from_message(self, message: str) -> str:\n",
    "        \"\"\"Extract error information from log message\"\"\"\n",
    "        import re\n",
    "        \n",
    "        error_patterns = [\n",
    "            r':\\s*(.+)$',  \n",
    "            r'failed:\\s*(.+)$', \n",
    "            r'error:\\s*(.+)$',  \n",
    "            r'exception:\\s*(.+)$'  \n",
    "        ]\n",
    "        \n",
    "        for pattern in error_patterns:\n",
    "            match = re.search(pattern, message, re.IGNORECASE)\n",
    "            if match:\n",
    "                error_text = match.group(1).strip()\n",
    "                if any(keyword in error_text.lower() for keyword in \n",
    "                      ['error', 'exception', 'failed', 'timeout', 'connection', 'refused', 'not found', 'invalid']):\n",
    "                    return error_text\n",
    "        \n",
    "        if any(keyword in message.lower() for keyword in \n",
    "              ['error', 'exception', 'failed', 'timeout', 'connection', 'refused', 'not found', 'invalid']):\n",
    "            return message\n",
    "        \n",
    "        return \"\"\n",
    "    \n",
    "    def _log_to_csv(self, level: str, message: str, error_message: str = \"\", \n",
    "                    data_size: int = 0, inconsistent_data_count: int = 0, machine_autofetch: str = None):\n",
    "        \"\"\"Log structured data to CSV and print to console\"\"\"\n",
    "        if machine_autofetch is None:\n",
    "            machine_autofetch = self.machine_ip\n",
    "        caller_info = self._get_caller_info()\n",
    "        \n",
    "        step_seconds = time.time() - self.last_step_time\n",
    "        self.last_step_time = time.time()\n",
    "        step_minutes = int(step_seconds // 60)\n",
    "        step_secs = int(step_seconds % 60)\n",
    "        step_duration = f\"{step_minutes}m {step_secs}s\"\n",
    "        \n",
    "        total_seconds_from_start = time.time() - self.start_time\n",
    "        total_duration_from_start = self._format_total_duration(total_seconds_from_start)\n",
    "        \n",
    "        log_entry = {\n",
    "            'asctime': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'levelname': level,\n",
    "            'filename': caller_info['filename'],\n",
    "            'funcName': caller_info['funcName'],\n",
    "            'lineno': caller_info['lineno'],\n",
    "            'scraper_name': self.scraper_name,\n",
    "            'source': self.source,\n",
    "            'schedule': self.schedule,\n",
    "            'machine_id': self.machine_id,\n",
    "            'job_id': self.job_id,\n",
    "            'category': self.current_category,\n",
    "            'subcategory': self.current_subcategory,\n",
    "            'product_url': self.current_product_url,\n",
    "            'step_duration': step_duration,\n",
    "            'total_duration_from_start': total_duration_from_start,\n",
    "            'status': self.current_status,\n",
    "            'error_message': error_message,\n",
    "            'data_size': data_size,\n",
    "            'inconsistent_data_count': inconsistent_data_count,\n",
    "            'machine_autofetch': machine_autofetch,\n",
    "            'message': message\n",
    "        }\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        console_msg = f\"{timestamp} - {level} - {message}\"\n",
    "        if error_message:\n",
    "            console_msg += f\" | Error: {error_message}\"\n",
    "        print(console_msg)\n",
    "        \n",
    "        try:\n",
    "            with open(self.csv_log_path, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=self.csv_fieldnames)\n",
    "                writer.writerow(log_entry)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to write to CSV log: {e}\")\n",
    "    \n",
    "    def set_context(self, category: str = \"\", subcategory: str = \"\", \n",
    "                   product_url: str = \"\", status: str = \"\"):\n",
    "        \"\"\"Update current context for logging\"\"\"\n",
    "        if category:\n",
    "            self.current_category = category\n",
    "        if subcategory:\n",
    "            self.current_subcategory = subcategory\n",
    "        if product_url:\n",
    "            self.current_product_url = product_url\n",
    "        if status:\n",
    "            self.current_status = status\n",
    "    \n",
    "    def log_info(self, message: str, data_size: int = 0, inconsistent_data_count: int = 0, machine_autofetch: str = None):\n",
    "        \"\"\"Log info level message\"\"\"\n",
    "        self._log_to_csv(\"INFO\", message, data_size=data_size, \n",
    "                        inconsistent_data_count=inconsistent_data_count, machine_autofetch=machine_autofetch)\n",
    "    \n",
    "    def log_warning(self, message: str, data_size: int = 0, inconsistent_data_count: int = 0, machine_autofetch: str = None):\n",
    "        \"\"\"Log warning level message\"\"\"\n",
    "        self._log_to_csv(\"WARNING\", message, data_size=data_size, \n",
    "                        inconsistent_data_count=inconsistent_data_count, machine_autofetch=machine_autofetch)\n",
    "    \n",
    "    def log_error(self, message: str, error: Exception = None, data_size: int = 0, \n",
    "                  inconsistent_data_count: int = 0, machine_autofetch: str = None):\n",
    "        \"\"\"Log error level message with proper error capture\"\"\"\n",
    "        error_message = \"\"\n",
    "        if error:\n",
    "            error_message = str(error)\n",
    "        else:\n",
    "            error_message = self._extract_error_from_message(message)\n",
    "        \n",
    "        self.set_context(status=\"fail\")\n",
    "        self._log_to_csv(\"ERROR\", message, error_message=error_message, \n",
    "                        data_size=data_size, inconsistent_data_count=inconsistent_data_count, machine_autofetch=machine_autofetch)\n",
    "    \n",
    "    def log_debug(self, message: str, data_size: int = 0, inconsistent_data_count: int = 0, machine_autofetch: str = None):\n",
    "        \"\"\"Log debug level message\"\"\"\n",
    "        self._log_to_csv(\"DEBUG\", message, data_size=data_size, \n",
    "                        inconsistent_data_count=inconsistent_data_count, machine_autofetch=machine_autofetch)\n",
    "    \n",
    "    def log_job_start(self, machine_autofetch: str = None):\n",
    "        \"\"\"Log job start\"\"\"\n",
    "        self.set_context(status=\"starting\")\n",
    "        self.log_info(f\"Job {self.job_id} started for {self.scraper_name}\", machine_autofetch=machine_autofetch)\n",
    "    \n",
    "    def log_job_end(self, total_data_size: int = 0, machine_autofetch: str = None):\n",
    "        \"\"\"Log job end with total duration\"\"\"\n",
    "        self.set_context(status=\"ending\")\n",
    "        end_time = time.time()\n",
    "        total_duration_seconds = end_time - self.start_time\n",
    "        duration_str = self._format_total_duration(total_duration_seconds)\n",
    "\n",
    "        self.log_info(f\"Job {self.job_id} completed. Total duration: {duration_str}\", \n",
    "                    data_size=total_data_size, machine_autofetch=machine_autofetch)\n",
    "    \n",
    "    def log_success(self, message: str, data_size: int = 0, machine_autofetch: str = None):\n",
    "        \"\"\"Log successful operation\"\"\"\n",
    "        self.set_context(status=\"success\")\n",
    "        self.log_info(message, data_size=data_size, machine_autofetch=machine_autofetch)\n",
    "\n",
    "class EverliRegistrationBot: \n",
    "    MAIL_TM_API = \"https://api.mail.tm\"\n",
    "    LOG_DIR = \"Everli_Scrapper__logs\"\n",
    "    def __init__(self):\n",
    "        self.machine_id = socket.gethostname()\n",
    "        self.job_id = str(uuid.uuid4())\n",
    "        self.logger = StructuredLogger(\n",
    "            log_dir=self.LOG_DIR,\n",
    "            scraper_name=\"everli_scraper\",\n",
    "            source=\"it.everli.com\",\n",
    "            schedule=\"daily\",  \n",
    "            machine_id=self.machine_id,\n",
    "            job_id=self.job_id\n",
    "        )\n",
    "        self.header_manager = HeaderManager(self.logger)\n",
    "        self.authentication_token = None  \n",
    "        self.session = requests.Session()  \n",
    "        self.last_keep_alive = time.time()\n",
    "        self._cleanup_old_logs()\n",
    "    def _cleanup_old_logs(self, retention_days: int = 7) -> None:\n",
    "        try:\n",
    "            cutoff_date = datetime.now() - timedelta(days=retention_days)\n",
    "            log_pattern = os.path.join(self.LOG_DIR, 'scraper_logs_*.csv')\n",
    "            for log_file in glob.glob(log_pattern):\n",
    "                try:\n",
    "                    file_date_str = os.path.basename(log_file).replace('scraper_logs_', '').replace('.csv', '')\n",
    "                    file_date = datetime.strptime(file_date_str, '%Y-%m-%d')\n",
    "                    if file_date < cutoff_date:\n",
    "                        os.remove(log_file)\n",
    "                        self.logger.log_info(f\"Removed old log file: {log_file}\")  \n",
    "                except (ValueError, OSError) as e:\n",
    "                        self.logger.log_warning(f\"Could not process log file {log_file}: {e}\") \n",
    "        except Exception as e:\n",
    "                self.logger.log_error(f\"Error during log cleanup\", e)\n",
    "    \n",
    "    @staticmethod\n",
    "    def human_delay(min_seconds: float = 0.5, max_seconds: float = 1.5) -> None:\n",
    "        \"\"\"Simulate human-like delays in automation.\"\"\"\n",
    "        delay = random.uniform(min_seconds, max_seconds)\n",
    "        time.sleep(delay)\n",
    "    def refresh_authentication(self, max_retries: int = 3, base_delay: float = 5.0) -> bool:\n",
    "        try:\n",
    "            self.logger.log_info(\"Attempting to extend session with keep-alive request\")\n",
    "            keep_alive_url = \"https://api.everli.com/sm/api/v3/stores?latitude=45.46427&longitude=9.18951\"\n",
    "            headers = self.get_headers_for_request(self.authentication_token, keep_alive_url)\n",
    "            params = {'skip': '0', 'take': '10'} \n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    response = self.session.get(keep_alive_url, headers=headers, params=params, timeout=10)\n",
    "                    if response.status_code == 200:\n",
    "                        self.logger.log_success(\"Session extended successfully via keep-alive request\")\n",
    "                        self.last_keep_alive = time.time()\n",
    "                        return True\n",
    "                    elif response.status_code == 429:\n",
    "                        delay = base_delay * (2 ** attempt)\n",
    "                        self.logger.log_warning(f\"Rate limited (429) on keep-alive attempt {attempt + 1}. Waiting {delay}s before retry.\")\n",
    "                        time.sleep(delay)\n",
    "                        continue\n",
    "                    elif response.status_code == 401:\n",
    "                        self.logger.log_warning(\"Keep-alive request failed with 401, attempting re-registration\")\n",
    "                        break\n",
    "                    else:\n",
    "                        self.logger.log_warning(f\"Keep-alive request failed with status {response.status_code}\")\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    self.logger.log_warning(f\"Keep-alive attempt {attempt + 1} failed: {e}\")\n",
    "                    if attempt < max_retries - 1:\n",
    "                        delay = base_delay * (2 ** attempt)\n",
    "                        self.logger.log_info(f\"Retrying keep-alive after {delay}s\")\n",
    "                        time.sleep(delay)\n",
    "                    continue\n",
    "            self.logger.log_info(\"Falling back to re-registration after keep-alive failures\")\n",
    "            try:\n",
    "                page, temp_profile = self.setup_browser()\n",
    "                page.get(\"https://it.everli.com/\")\n",
    "                time.sleep(2)\n",
    "                self.logout_current_session(page)\n",
    "                page.quit()\n",
    "                if temp_profile and os.path.exists(temp_profile):\n",
    "                    shutil.rmtree(temp_profile)\n",
    "                    self.logger.log_info(f\"Cleaned up temp profile before re-registration: {temp_profile}\")\n",
    "            except Exception as e:\n",
    "                self.logger.log_warning(f\"Failed to fully logout: {e}\")\n",
    "\n",
    "            new_token = self.register_and_confirm()\n",
    "            if new_token and new_token != 'null':\n",
    "                self.authentication_token = new_token\n",
    "                self.session.cookies.set('vAuthToken', new_token, domain='it.everli.com')\n",
    "                self.logger.log_success(f\"New vAuthToken obtained: {new_token}\")\n",
    "                self.last_keep_alive = time.time()\n",
    "                return True\n",
    "            else:\n",
    "                self.logger.log_error(\"Failed to obtain new valid token\")\n",
    "                return False\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.log_error(f\"Re-registration failed: {e}\")\n",
    "            return False\n",
    "    def create_temporary_email(self) -> Tuple[str, str, str]:\n",
    "        \"\"\"Create a temporary email account using Mail.tm API.\"\"\"\n",
    "        max_retries = 3\n",
    "        base_delay = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                self.logger.log_info(f\"Creating temporary email account (attempt {attempt + 1})\")\n",
    "                \n",
    "                response = requests.get(f\"{self.MAIL_TM_API}/domains\", timeout=10)\n",
    "                response.raise_for_status()\n",
    "                domain = response.json()[\"hydra:member\"][0][\"domain\"]\n",
    "                \n",
    "                local_part = \"\".join(\n",
    "                    random.choices(\"abcdefghijklmnopqrstuvwxyz0123456789\", k=10)\n",
    "                )\n",
    "                email = f\"{local_part}@{domain}\"\n",
    "                password = \"PASworrd@123!\"\n",
    "                \n",
    "                create_response = requests.post(\n",
    "                    f\"{self.MAIL_TM_API}/accounts\",\n",
    "                    json={\"address\": email, \"password\": password},\n",
    "                    timeout=10\n",
    "                )\n",
    "                create_response.raise_for_status()\n",
    "                token_response = requests.post(\n",
    "                    f\"{self.MAIL_TM_API}/token\",\n",
    "                    json={\"address\": email, \"password\": password},\n",
    "                    timeout=10\n",
    "                )\n",
    "                token_response.raise_for_status()\n",
    "                email_token = token_response.json()[\"token\"]\n",
    "                \n",
    "                self.logger.log_info(f\"Successfully created temporary email: {email}\")\n",
    "                return email, password, email_token\n",
    "            except Exception as e:\n",
    "                self.logger.log_warning(f\"Mail.tm creation attempt {attempt + 1} failed: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = base_delay * (2 ** attempt)  \n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    self.logger.log_error(\"Failed to create temporary email after all retries\")\n",
    "                    raise Exception(\"Could not create temporary email account\")\n",
    "    def poll_for_confirmation_email(self, email_token: str, timeout: int = 300) -> str:\n",
    "        \"\"\"Poll Mail.tm for confirmation email with verification link.\"\"\"\n",
    "        deadline = time.time() + timeout\n",
    "        poll_interval = 10\n",
    "        \n",
    "        self.logger.log_info(f\"Polling for confirmation email (timeout: {timeout}s)\")\n",
    "        \n",
    "        while time.time() < deadline:\n",
    "            try:\n",
    "                headers = {\"Authorization\": f\"Bearer {email_token}\"}\n",
    "                response = requests.get(f\"{self.MAIL_TM_API}/messages\", headers=headers, timeout=10)\n",
    "                response.raise_for_status()\n",
    "                messages = response.json().get(\"hydra:member\", [])\n",
    "                if messages:\n",
    "                    message_id = messages[0][\"id\"]\n",
    "                    msg_response = requests.get(f\"{self.MAIL_TM_API}/messages/{message_id}\",headers=headers,timeout=10)\n",
    "                    msg_response.raise_for_status()\n",
    "                    message = msg_response.json()\n",
    "                    content = message.get(\"html\") or message.get(\"text\") or \"\"\n",
    "                    if isinstance(content, list):\n",
    "                        content = \"\".join(content)\n",
    "                    match = re.search(r'(https://it\\.everli\\.com[^\\s\"<]+)', content)\n",
    "                    if match and match.group(1) != \"https://it.everli.com/\":\n",
    "                        link = match.group(1)\n",
    "                        self.logger.log_success(f\"Found confirmation link: {link}\")\n",
    "                        self.logger.set_context(product_url=link)\n",
    "                        return link\n",
    "                    fallback_match = re.search(r'https://[^\\s\"<]+', content)\n",
    "                    if fallback_match and fallback_match.group(0) != \"https://it.everli.com/\":\n",
    "                        link = fallback_match.group(0)\n",
    "                        self.logger.log_info(f\"Using fallback confirmation link: {link}\")\n",
    "                        self.logger.set_context(product_url=link)\n",
    "                        return link\n",
    "                    self.logger.log_debug(\"Email received but no usable confirmation link found\")\n",
    "            except Exception as e:\n",
    "                self.logger.log_warning(f\"Error while polling for email: {e}\")\n",
    "            time.sleep(poll_interval)\n",
    "        raise RuntimeError(f\"No confirmation email received within {timeout} seconds\")\n",
    "    def type_text_humanlike(self, element, text: str, delay: float = 0.1) -> None:\n",
    "        \"\"\"Type text into an element with human-like delays between characters.\"\"\"\n",
    "        try:\n",
    "            element.clear()\n",
    "            for char in text:\n",
    "                element.input(char)\n",
    "                time.sleep(delay)\n",
    "            self.logger.log_debug(f\"Successfully typed text into element\")\n",
    "        except Exception as e:\n",
    "            self.logger.log_error(f\"Failed to type text: {e}\")\n",
    "            raise\n",
    "    def wait_for_password_input(self, page, max_attempts: int = 10) -> object:\n",
    "        \"\"\"Wait for password input field to appear on the page.\"\"\"\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                inputs = page.eles(\"tag:input\")\n",
    "                for input_elem in inputs:\n",
    "                    if input_elem.attrs.get(\"type\") == \"password\":\n",
    "                        self.logger.log_info(\"Password input field found\")\n",
    "                        return input_elem\n",
    "                \n",
    "                self.logger.log_debug(f\"Password input not found, attempt {attempt + 1}\")\n",
    "                time.sleep(2)\n",
    "            except Exception as e:\n",
    "                self.logger.log_warning(f\"Error while searching for password input: {e}\")\n",
    "                time.sleep(2)\n",
    "        raise Exception(\"Password input field not found after maximum attempts\")\n",
    "    def click_continue_with_email(self, page, max_attempts: int = 10) -> None:\n",
    "        \"\"\"Find and click the 'Continue with Email' button.\"\"\"\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                self.logger.log_debug(f\"Looking for 'Continue with Email' button (attempt {attempt + 1})\")\n",
    "                buttons = page.eles(\"tag:button\")\n",
    "                for button in buttons:\n",
    "                    button_text = button.text.strip().lower()\n",
    "                    if \"continue with email\" in button_text:\n",
    "                        page.run_js(\n",
    "                            'arguments[0].scrollIntoView({behavior: \"smooth\", block: \"center\"});',\n",
    "                            button,\n",
    "                        )\n",
    "                        time.sleep(1)\n",
    "                        \n",
    "                        button.click()\n",
    "                        self.logger.log_success(\"Successfully clicked 'Continue with Email' button\")\n",
    "                        return\n",
    "                time.sleep(2)\n",
    "            except Exception as e:\n",
    "                self.logger.log_warning(f\"Error clicking continue button: {e}\")\n",
    "                time.sleep(2)\n",
    "        raise Exception(\"'Continue with Email' button not found or not clickable\")\n",
    "    def setup_browser(self) -> Tuple[ChromiumPage, str]:\n",
    "        \"\"\"Set up Chrome browser with temporary profile.\"\"\"\n",
    "        try:\n",
    "            temp_profile = tempfile.mkdtemp(prefix=\"everli_profile_\")\n",
    "            options = ChromiumOptions()\n",
    "            options.headless(False)\n",
    "            options.set_argument(\"--start-maximized\")\n",
    "            options.set_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "            options.set_argument(\"--disable-extensions\")\n",
    "            options.set_user_data_path(temp_profile)\n",
    "            page = ChromiumPage(options)\n",
    "            self.logger.log_info(f\"Browser initialized with temp profile: {temp_profile}\")\n",
    "            return page, temp_profile\n",
    "        except Exception as e:\n",
    "            self.logger.log_error(f\"Failed to setup browser: {e}\")\n",
    "            raise\n",
    "    def extract_token_from_page(self, page) -> Optional[str]:\n",
    "        \"\"\"Extract vAuthToken using the SimplifiedTokenExtractor\"\"\"\n",
    "        try:\n",
    "            token_extractor = SimplifiedTokenExtractor(page, self.logger)\n",
    "            token = token_extractor.extract_vauth_token_from_cookies()\n",
    "            return token\n",
    "        except Exception as e:\n",
    "            self.logger.log_error(f\"Error extracting token: {e}\")\n",
    "            return None\n",
    "    def logout_current_session(self, page):\n",
    "        try:\n",
    "            self.logger.log_info(\"Attempting to clear session before logout\")\n",
    "            page.run_js(\"window.localStorage.clear();\")\n",
    "            page.run_js(\"window.sessionStorage.clear();\")\n",
    "            page.delete_all_cookies()\n",
    "            self.logger.log_success(\"Cleared cookies and storage\")\n",
    "        except Exception as e:\n",
    "            self.logger.log_warning(f\"Error while clearing session data: {e}\")\n",
    "\n",
    "\n",
    "    def register_and_confirm(self) -> Optional[str]:\n",
    "        page = None\n",
    "        temp_profile = None\n",
    "        try:\n",
    "            # Step 1: Create temporary email\n",
    "            self.logger.log_info(\"Starting Everli account registration process\")\n",
    "            email, password, email_token = self.create_temporary_email()\n",
    "            # Step 2: Setup browser\n",
    "            page, temp_profile = self.setup_browser()\n",
    "            self.page=page\n",
    "            # Step 3: Navigate to Everli and handle cookies\n",
    "            self.logger.log_info(\"Navigating to Everli website\")\n",
    "            page.get(\"https://it.everli.com/\")\n",
    "            self.human_delay()\n",
    "            # Accept cookies\n",
    "            try:\n",
    "                accept_button = page.ele('x://button[contains(text(), \"Accept\")]', timeout=5)\n",
    "                if accept_button:\n",
    "                    accept_button.click()\n",
    "                    self.logger.log_success(\"Cookie consent accepted\")\n",
    "            except Exception:\n",
    "                self.logger.log_debug(\"No cookie consent dialog found\")\n",
    "            # Step 4: Enter address and select Lidl\n",
    "            self.logger.log_info(\"Entering address and selecting store\")\n",
    "            try:\n",
    "                address_input = page.ele('css:input[placeholder*=\"via Marco Polo\"]', timeout=10)\n",
    "                address_input.click()\n",
    "                address_input.clear()\n",
    "                address_input.input(\"3,via Gaudenzio Ferrari, Milano\")\n",
    "                self.human_delay(1, 2)\n",
    "                address_input.input(\"\\ue015\\ue007\")\n",
    "                time.sleep(4)\n",
    "                # Select Lidl\n",
    "                lidl_found = False\n",
    "                for attempt in range(5):\n",
    "                    try:\n",
    "                        lidl_element = page.ele('x://span[contains(text(),\"Lidl\")]', timeout=2)\n",
    "                        if lidl_element:\n",
    "                            page.run_js(\n",
    "                                'arguments[0].scrollIntoView({behavior: \"smooth\", block: \"center\"});',\n",
    "                                lidl_element,\n",
    "                            )\n",
    "                            time.sleep(1)\n",
    "                            lidl_element.click()\n",
    "                            self.logger.log_success(\"Lidl store selected\")\n",
    "                            lidl_found = True\n",
    "                            break\n",
    "                    except Exception:\n",
    "                        time.sleep(1)\n",
    "                if not lidl_found:\n",
    "                    raise Exception(\"Could not find or select Lidl store\") \n",
    "            except Exception as e:\n",
    "                self.logger.log_error(f\"Failed to set address/store: {e}\")\n",
    "                raise\n",
    "            \n",
    "            # Step 5: Open registration modal\n",
    "            self.logger.log_info(\"Opening registration modal\")\n",
    "            try:\n",
    "                menu_button = page.ele(\"css:svg.is-ico-menu\", timeout=10)\n",
    "                menu_button.click()\n",
    "                login_selectors = [\n",
    "                    \"//button[contains(text(),'Sign up') or contains(text(),'Registrati')]\",\n",
    "                    \"//span[contains(text(),'Sign up') or contains(text(),'Registrati')]\",\n",
    "                    \"//div[contains(text(),'Sign up') or contains(text(),'Log in')]\",\n",
    "                    \"//*[contains(text(),'Log in') or contains(text(),'Accedi')]\",\n",
    "                ]\n",
    "                modal_opened = False\n",
    "                for selector in login_selectors:\n",
    "                    try:\n",
    "                        element = page.ele(f\"x:{selector}\", timeout=2)\n",
    "                        if element:\n",
    "                            element.click()\n",
    "                            self.logger.log_success(f\"Registration modal opened using selector: {selector}\")\n",
    "                            modal_opened = True\n",
    "                            break\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                if not modal_opened:\n",
    "                    raise Exception(\"Could not open registration modal\")  \n",
    "            except Exception as e:\n",
    "                self.logger.log_error(f\"Failed to open registration modal: {e}\")\n",
    "                raise\n",
    "            self.logger.log_info(\"Entering email address\")\n",
    "            try:\n",
    "                email_input = page.ele('css:input[type=\"email\"]', timeout=10)\n",
    "                email_input.clear()\n",
    "                self.type_text_humanlike(email_input, email)\n",
    "                self.human_delay()\n",
    "                self.click_continue_with_email(page)\n",
    "            except Exception as e:\n",
    "                self.logger.log_error(f\"Failed to enter email: {e}\")\n",
    "                raise\n",
    "            # Step 7: Enter password and submit\n",
    "            self.logger.log_info(\"Entering password and submitting form\")\n",
    "            try:\n",
    "                password_input = self.wait_for_password_input(page)\n",
    "                self.type_text_humanlike(password_input, password)\n",
    "                self.human_delay()\n",
    "                submit_button = page.ele('css:button.vader-button[type=\"submit\"]', timeout=10)\n",
    "                submit_button.click()\n",
    "                self.logger.log_success(\"Registration form submitted\")\n",
    "            except Exception as e:\n",
    "                self.logger.log_error(f\"Failed to submit registration form: {e}\")\n",
    "                raise\n",
    "            # Step 8: Get confirmation link and complete login flow\n",
    "            self.logger.log_info(\"Waiting for confirmation email\")\n",
    "            try:\n",
    "                confirmation_link = self.poll_for_confirmation_email(email_token)\n",
    "                self.logger.log_info(f\"Following confirmation link: {confirmation_link}\")\n",
    "                # Navigate to confirmation link\n",
    "                page.get(confirmation_link)\n",
    "                page.wait.load_start()\n",
    "                # Wait for initial page load\n",
    "                self.logger.log_info(\"Waiting for email confirmation page to load...\")\n",
    "                time.sleep(5)\n",
    "                # Look for confirmation success and automatic redirect/login\n",
    "                self.logger.log_info(\"Waiting for automatic login after email confirmation...\")\n",
    "                # Check if we're redirected to main site (logged in)\n",
    "                max_wait_time = 60  \n",
    "                login_detected = False\n",
    "                start_time = time.time()\n",
    "                while time.time() - start_time < max_wait_time:\n",
    "                    current_url = page.url\n",
    "                    self.logger.log_debug(f\"Current URL: {current_url}\")\n",
    "                    if 'registration-email-confirm' not in current_url:\n",
    "                        self.logger.log_success(\"Detected redirect from confirmation page - login likely successful\")\n",
    "                        login_detected = True\n",
    "                        token_extractor = SimplifiedTokenExtractor(page, self.logger)\n",
    "                        self.authentication_token = token_extractor.extract_vauth_token_from_cookies()\n",
    "                        if self.authentication_token:\n",
    "                            self.logger.log_success(f\"vAuthToken extracted successfully: {self.authentication_token}\")\n",
    "                        else:\n",
    "                            self.logger.log_warning(\"vAuthToken not found in cookies after redirect\")\n",
    "                        break\n",
    "                    time.sleep(2)               \n",
    "                if self.authentication_token and self.authentication_token != 'null':\n",
    "                    self.logger.log_success(f\"Successfully extracted vAuthToken: {self.authentication_token}\")\n",
    "                    time.sleep(15)\n",
    "            except Exception as e:\n",
    "                self.logger.log_error(f\"Failed to confirm email or extract token: {e}\")\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            self.logger.log_error(f\"Registration process failed: {e}\")\n",
    "        finally:\n",
    "            if page:\n",
    "                try:\n",
    "                    # time.sleep(2)\n",
    "                    # page.quit()\n",
    "                    self.logger.log_info(\"Browser session closed\")\n",
    "                except Exception as e:\n",
    "                    self.logger.log_warning(f\"Error closing browser: {e}\")\n",
    "            if temp_profile and os.path.exists(temp_profile):\n",
    "                try:\n",
    "                    shutil.rmtree(temp_profile)\n",
    "                    self.logger.log_success(f\"Temporary profile cleaned up: {temp_profile}\")\n",
    "                except Exception as e:\n",
    "                    self.logger.log_warning(f\"Error cleaning up temp profile: {e}\")\n",
    "        return self.authentication_token\n",
    "    def get_headers_for_request(self, authentication_token: str = None, endpoint_url: str = '') -> Dict[str, str]:\n",
    "        \"\"\"Get properly formatted headers for API requests with fresh session data.\"\"\"\n",
    "        token_to_use = authentication_token or self.authentication_token\n",
    "        if not token_to_use or token_to_use == 'null':\n",
    "            self.logger.log_error(\"No valid authentication token available for headers\")\n",
    "            return self.header_manager.generate_base_headers()\n",
    "        headers = self.header_manager.get_headers_for_api_call(\n",
    "            authentication_token=token_to_use,\n",
    "            request_type='GET',\n",
    "            endpoint_url=endpoint_url\n",
    "        )\n",
    "        headers['x-timestamp'] = str(int(time.time()))\n",
    "        headers['x-request-time'] = datetime.now().isoformat()\n",
    "        \n",
    "        return headers\n",
    "def main_execution():\n",
    "    start_index = 0\n",
    "    stores_done = []\n",
    "    master_csv_path = \"Everli_Data_Products.csv\"\n",
    "    checkpoint_file = \"scraper_check.json\"\n",
    "    data_products = pd.DataFrame()\n",
    "    bot = EverliRegistrationBot()\n",
    "    bot.logger.log_job_start()\n",
    "    total_data_size = 0\n",
    "\n",
    "    # Load checkpoint if exists\n",
    "    checkpoint = {'store_index': 0, 'category_index': 0, 'last_processed_product_id': None}\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        try:\n",
    "            with open(checkpoint_file, 'r') as f:\n",
    "                checkpoint = json.load(f)\n",
    "            start_index = checkpoint['store_index']\n",
    "            bot.logger.log_info(f\"Loaded checkpoint: Starting from store index {start_index}, category index {checkpoint['category_index']}\")\n",
    "        except Exception as e:\n",
    "            bot.logger.log_warning(f\"Failed to load checkpoint: {e}. Starting from scratch.\")\n",
    "    # Load existing products to prevent duplicates\n",
    "    existing_products = set()\n",
    "    if os.path.exists(master_csv_path):\n",
    "        try:\n",
    "            existing_df = pd.read_csv(master_csv_path)\n",
    "            if 'id' in existing_df.columns:\n",
    "                existing_products = set(existing_df['id'].astype(str))\n",
    "            bot.logger.log_info(f\"Loaded {len(existing_products)} existing product IDs from {master_csv_path}\")\n",
    "        except Exception as e:\n",
    "            bot.logger.log_warning(f\"Failed to load existing products: {e}\")\n",
    "    # Obtain authentication token\n",
    "    authentication_token = bot.register_and_confirm()\n",
    "    if not authentication_token or authentication_token == 'null':\n",
    "        bot.logger.log_error(\"Failed to obtain valid vAuthToken. Exiting.\")\n",
    "        bot.logger.log_job_end(total_data_size)\n",
    "        return\n",
    "    bot.logger.log_success(f\"vAuthToken obtained successfully: {authentication_token}\")\n",
    "    headers = bot.get_headers_for_request(authentication_token)\n",
    "    while start_index < len(stores):\n",
    "        i = start_index\n",
    "        start_time = datetime.now()\n",
    "        bot.logger.log_info(f\"Start processing Store {i} - {stores['name'][i]}\")\n",
    "        try:\n",
    "            product_full_batch = pd.DataFrame()\n",
    "            area_id = stores['area_id'][i]\n",
    "            url_id = stores['Url_id'][i]\n",
    "            currency_id = stores['currency_id'][i]\n",
    "            country_id = stores['country_id'][i]\n",
    "            src_id = stores['src_id'][i]\n",
    "            store_link = stores['link'][i].replace('everli://app', '')\n",
    "            page = f\"https://api.everli.com/sm/api/v3/{store_link}/categories/tree\"\n",
    "            # Make API request for categories\n",
    "            resp = requests.get(page, headers=headers)\n",
    "            if resp.status_code == 429:\n",
    "                bot.logger.log_error(\"Got 429 error at store level. Refreshing token and retrying.\")\n",
    "                if bot.refresh_authentication():\n",
    "                    authentication_token = bot.authentication_token\n",
    "                    headers = bot.get_headers_for_request(authentication_token)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise Exception(\"Failed to refresh authentication token\")\n",
    "            if resp.status_code != 200:\n",
    "                raise Exception(f\"Blocked or invalid token (status {resp.status_code})\")\n",
    "            categories_json = resp.json()\n",
    "            categories_list = []\n",
    "            for h in range(len(categories_json['data']['menu'])):\n",
    "                if 'items' in categories_json['data']['menu'][h]:\n",
    "                    ind = h\n",
    "                    cat_list = categories_json['data']['menu'][ind]['items']\n",
    "                    for cat in cat_list:\n",
    "                        parent_name = cat['name']\n",
    "                        categories_list.append({'name': parent_name, 'link': cat['link'], 'parent_name': ''})\n",
    "                        for sub_cat in cat.get('branch', []):\n",
    "                            categories_list.append({'name': sub_cat['name'], 'link': sub_cat['link'], 'parent_name': parent_name})\n",
    "            categories_df = pd.DataFrame(categories_list)\n",
    "            categories_df = categories_df[categories_df['parent_name'] != ''].reset_index(drop=True)\n",
    "            bot.logger.log_success(f\"Categories found: {len(categories_df)}\")\n",
    "            products_from_all_categories = pd.DataFrame()\n",
    "            # Start from checkpoint category index\n",
    "            j = checkpoint.get('category_index', 0)\n",
    "            while j < len(categories_df):\n",
    "                try:\n",
    "                    bot.logger.set_context(category=cat, subcategory=sub_cat)\n",
    "                    bot.logger.log_info(f\"Scraping category {j+1}/{len(categories_df)} - {categories_df.loc[j, 'name']}\")\n",
    "                    cat = categories_df.loc[j, 'parent_name']\n",
    "                    sub_cat = categories_df.loc[j, 'name']\n",
    "                    cat_link = categories_df.loc[j, 'link'].replace('#/', '')\n",
    "                    params = {'take': '100000000', 'skip': '0'}\n",
    "                    time.sleep(1.5)\n",
    "                    prod_resp = requests.get(f\"https://api.everli.com/sm/api/v3/{cat_link}\", params=params, headers=headers)\n",
    "                    if prod_resp.status_code == 429:\n",
    "                        bot.logger.log_debug(f\"429 error at category {j} — refreshing token and retrying\")\n",
    "                        if bot.refresh_authentication():\n",
    "                            authentication_token = bot.authentication_token\n",
    "                            headers = bot.get_headers_for_request(authentication_token)\n",
    "                            continue\n",
    "                        else:\n",
    "                            raise Exception(\"Failed to refresh authentication token\")\n",
    "                    prod_resp.raise_for_status()\n",
    "                    prod_data = prod_resp.json()\n",
    "                    subcategory_products = pd.DataFrame()\n",
    "                    # Process products in the category\n",
    "                    product_list = []\n",
    "                    for block in prod_data['data']['body']:\n",
    "                        if block.get('widget_type') == 'vertical-list':\n",
    "                            product_list.extend(block.get('list', []))\n",
    "                    # Filter out already processed products\n",
    "                    start_processing = True if not checkpoint.get('last_processed_product_id') else False\n",
    "                    products_processed=0\n",
    "                    for product in product_list:\n",
    "                        product_id = str(product.get('id'))\n",
    "                        if product_id == checkpoint.get('last_processed_product_id'):\n",
    "                            start_processing = True\n",
    "                            continue\n",
    "                        if start_processing and product_id not in existing_products:\n",
    "                            product_df = pd.json_normalize([product])\n",
    "                            product_df['cat_name_org'] = cat\n",
    "                            product_df['sub_cat_name_org'] = sub_cat\n",
    "                            product_df['nw'] = datetime.now(zone_dubai).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                            subcategory_products = pd.concat([subcategory_products, product_df])\n",
    "                            existing_products.add(product_id)\n",
    "                            products_processed += 1\n",
    "\n",
    "\n",
    "                    if not subcategory_products.empty:\n",
    "                        products_from_all_categories = pd.concat([products_from_all_categories, subcategory_products])\n",
    "                        product_size = len(subcategory_products.to_csv(index=False).encode('utf-8'))\n",
    "                        total_data_size += product_size\n",
    "                        bot.logger.log_success(f\"Processed {products_processed} products from category {sub_cat}\", \n",
    "                                             data_size=product_size)\n",
    "                    # Update checkpoint after each category\n",
    "                    checkpoint = {\n",
    "                        'store_index': i,\n",
    "                        'category_index': j + 1,\n",
    "                        'last_processed_product_id': None\n",
    "                    }\n",
    "                    with open(checkpoint_file, 'w') as f:\n",
    "                        json.dump(checkpoint, f)\n",
    "                    bot.logger.log_debug(f\"Updated checkpoint: store {i}, category {j+1}\")\n",
    "                    j += 1\n",
    "                except Exception as e:\n",
    "                    bot.logger.log_error(f\"Error at category {j}: {str(e)}\")\n",
    "                    # Save checkpoint with last processed product\n",
    "                    if subcategory_products.empty:\n",
    "                        checkpoint['last_processed_product_id'] = None\n",
    "                    else:\n",
    "                        last_product_id = str(subcategory_products['id'].iloc[-1]) if 'id' in subcategory_products.columns else None\n",
    "                        checkpoint['last_processed_product_id'] = last_product_id\n",
    "                    with open(checkpoint_file, 'w') as f:\n",
    "                        json.dump(checkpoint, f)\n",
    "                    bot.logger.log_debug(f\"Checkpoint saved due to error: {checkpoint}\")\n",
    "                    if \"429\" in str(e):\n",
    "                        bot.logger.log_error(\"Got 429 error at category level. Refreshing token.\")\n",
    "                        if bot.refresh_authentication():\n",
    "                            authentication_token = bot.authentication_token\n",
    "                            headers = bot.get_headers_for_request(authentication_token)\n",
    "                            time.sleep(5)\n",
    "                            continue\n",
    "                        else:\n",
    "                            bot.logger.log_error(\"Failed to refresh authentication token. Moving to next store.\")\n",
    "                            start_index += 1\n",
    "                            checkpoint = {'store_index': start_index, 'category_index': 0, 'last_processed_product_id': None}\n",
    "                            with open(checkpoint_file, 'w') as f:\n",
    "                                json.dump(checkpoint, f)\n",
    "                            break\n",
    "                    else:\n",
    "                        bot.logger.log_info(\"Retrying category after error...\")\n",
    "                        if bot.refresh_authentication():\n",
    "                            authentication_token = bot.authentication_token\n",
    "                            headers = bot.get_headers_for_request(authentication_token)\n",
    "                            time.sleep(5)\n",
    "                            continue\n",
    "                        else:\n",
    "                            bot.logger.log_error(\"Failed to refresh authentication token. Moving to next store.\")\n",
    "                            start_index += 1\n",
    "                            checkpoint = {'store_index': start_index, 'category_index': 0, 'last_processed_product_id': None}\n",
    "                            with open(checkpoint_file, 'w') as f:\n",
    "                                json.dump(checkpoint, f)\n",
    "                            break\n",
    "            if not products_from_all_categories.empty:\n",
    "                product_full_batch = products_from_all_categories.copy()\n",
    "                product_full_batch['store_name'] = stores['name'][i]\n",
    "                product_full_batch['store_id'] = stores['id'][i]\n",
    "                product_full_batch['source_file_id'] = source_file_ID\n",
    "                product_full_batch['url_id'] = url_id\n",
    "                product_full_batch['currency_id'] = currency_id\n",
    "                product_full_batch['area_id'] = area_id\n",
    "                product_full_batch['country_id'] = country_id\n",
    "                product_full_batch['src_id'] = src_id\n",
    "                # Append to CSV\n",
    "                product_full_batch.to_csv(\n",
    "                    master_csv_path,\n",
    "                    mode='a',\n",
    "                    index=False,\n",
    "                    header=not os.path.exists(master_csv_path)\n",
    "                )\n",
    "                data_products = pd.concat([data_products, product_full_batch], ignore_index=True)\n",
    "                batch_size = len(product_full_batch.to_csv(index=False).encode('utf-8'))\n",
    "                bot.logger.log_success(f\"Appended {len(product_full_batch)} products to {master_csv_path}\", \n",
    "                                     data_size=batch_size)\n",
    "                stores_done.append(i)\n",
    "            else:\n",
    "                bot.logger.log_error(f\"No data saved for store {i}: empty product set\")\n",
    "\n",
    "            duration = round((datetime.now() - start_time).total_seconds() / 60, 2)\n",
    "            bot.logger.log_info(f\"Duration for store {i}: {duration} min\")\n",
    "            start_index += 1\n",
    "            checkpoint = {'store_index': start_index, 'category_index': 0, 'last_processed_product_id': None}\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                json.dump(checkpoint, f)\n",
    "        except Exception as e:\n",
    "            bot.logger.log_error(f\"Critical error at store {i}: {str(e)}\")\n",
    "            checkpoint['store_index'] = i\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                json.dump(checkpoint, f)\n",
    "            if \"429\" in str(e):\n",
    "                bot.logger.log_error(\"Got 429 error at store level. Refreshing token and retrying.\")\n",
    "                if bot.refresh_authentication():\n",
    "                    authentication_token = bot.authentication_token\n",
    "                    headers = bot.get_headers_for_request(authentication_token)\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "                else:\n",
    "                    bot.logger.log_error(\"Failed to refresh authentication token. Moving to next store.\")\n",
    "                    start_index += 1\n",
    "                    checkpoint = {'store_index': start_index, 'category_index': 0, 'last_processed_product_id': None}\n",
    "                    with open(checkpoint_file, 'w') as f:\n",
    "                        json.dump(checkpoint, f)\n",
    "            else:\n",
    "                bot.logger.log_info(\"Retrying store after error...\")\n",
    "                if bot.refresh_authentication():\n",
    "                    authentication_token = bot.authentication_token\n",
    "                    headers = bot.get_headers_for_request(authentication_token)\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "                else:\n",
    "                    bot.logger.log_error(\"Failed to refresh authentication token. Moving to next store.\")\n",
    "                    start_index += 1\n",
    "                    checkpoint = {'store_index': start_index, 'category_index': 0, 'last_processed_product_id': None}\n",
    "                    with open(checkpoint_file, 'w') as f:\n",
    "                        json.dump(checkpoint, f)\n",
    "    bot.logger.log_job_end(total_data_size)\n",
    "   \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6180be83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
